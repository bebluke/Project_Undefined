import faiss
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer

# **è¼‰å…¥èªæ„æ¨¡å‹**
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2', device='cuda')

# **è®€å– FAISS ç´¢å¼•**
index = faiss.read_index("faiss_index_ivf_new.bin")

# **è®€å–è©•è«–æ•¸æ“š**
df_comments = pd.read_csv("cleaned_comments_new.csv", usecols=["review_id", "location_id", "comments", "language"])

# **è®€å–åœ°é»è³‡è¨Š**
df_info = pd.read_json("E_838_location_info.json")
df_info = df_info.rename(columns={"location_id": "location_id", "gmap_location": "gmap_location"})

# **è®€å– FAISS review_id å°æ‡‰**
review_ids = np.load("review_ids_new.npy")  # FAISS å°æ‡‰çš„ review_id


def retrieve_similar_places(locations, semantic_keywords):
    """
    é‡å° `locations` æ¸…å–®ï¼Œä½¿ç”¨ `semantic_keywords` é€²è¡Œ FAISS æª¢ç´¢ï¼Œç¢ºä¿ `gmap_location` åªå‡ºç¾ä¸€æ¬¡
    """
    print("ğŸ“ FAISS æª¢ç´¢é–‹å§‹...")
    print(f"ğŸ—º é™åˆ¶æª¢ç´¢çš„åœ°é»æ•¸é‡: {len(locations)}")
    print(f"ğŸ”‘ ä½¿ç”¨èªæ„é—œéµè©: {semantic_keywords}")

    if not locations or not semantic_keywords:
        print("ğŸš¨ æ²’æœ‰åœ°é»æˆ–èªæ„é—œéµå­—ï¼Œè·³é FAISS æª¢ç´¢ã€‚")
        return []

    selected_locations = [loc["location_id"] for loc in locations]

    # **ç¯©é¸ç¬¦åˆçš„è©•è«–**
    filtered_comments = df_comments[df_comments["location_id"].isin(selected_locations)]
    print(f"ğŸ” ç¬¦åˆæ¢ä»¶çš„è©•è«–æ•¸é‡: {len(filtered_comments)}")

    if filtered_comments.empty:
        print("ğŸš¨ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è©•è«–ï¼ŒFAISS è·³éï¼")
        return []

    # **å‘é‡åŒ– `semantic_keywords`**
    query_vector = model.encode([" ".join(semantic_keywords)]).astype('float32')

    # **è¨­å®šæœ€å¤§æª¢ç´¢è©•è«–æ•¸é‡**
    k = min(100, len(filtered_comments))

    # **åŸ·è¡Œ FAISS èªæ„æª¢ç´¢**
    distances, indices = index.search(query_vector, k)

    # **ç¢ºä¿ FAISS æª¢ç´¢çµæœæ•¸é‡æ­£ç¢º**
    valid_indices = [i for i in indices[0] if i >= 0]
    if not valid_indices:
        print("ğŸš¨ FAISS æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„è©•è«–ã€‚")
        return []

    # **ä½¿ç”¨ review_id ä¾†ç¢ºä¿ç´¢å¼•å°æ‡‰**
    retrieved_review_ids = [review_ids[i] for i in valid_indices]

    # **ç¯©é¸ç¬¦åˆçš„è©•è«–**
    similar_reviews = filtered_comments[filtered_comments["review_id"].isin(retrieved_review_ids)].copy()

    # **åˆä½µåœ°é»åç¨±**
    df_merged = similar_reviews.merge(df_info[['location_id', 'gmap_location']], on='location_id', how='left')

    # **è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸**
    df_merged["similarity_score"] = 1 / (1 + distances[0][:len(df_merged)])

    # **æ‡‰ç”¨ Softmax åŠ æ¬Š**
    alpha = 5
    exp_scores = np.exp(df_merged["similarity_score"] * alpha)
    df_merged["weight"] = exp_scores / exp_scores.sum()

    # **åˆä½µç›¸åŒ `gmap_location`ï¼Œç¢ºä¿åœ°é»åªå‡ºç¾ä¸€æ¬¡**
    location_scores = df_merged.groupby(["gmap_location", "location_id"])["weight"].sum().reset_index()
    location_scores = location_scores.sort_values(by="weight", ascending=False)

    # **ä¿ç•™æœ€ç›¸ä¼¼çš„è©•è«–ï¼ˆä½†ä¸é‡è¤‡åœ°é»ï¼‰**
    best_reviews = df_merged.sort_values(by="weight", ascending=False).drop_duplicates(subset=["gmap_location"])

    # **å›å‚³çµæœï¼ˆæœ€å¤š 10 ç­†ï¼‰**
    results = []
    for idx, row in location_scores.head(10).iterrows():
        matched_review = best_reviews[best_reviews["gmap_location"] == row["gmap_location"]].iloc[0]
        results.append({
            "location_id": row["location_id"],
            "gmap_location": row["gmap_location"],
            "comments": matched_review["comments"],  # åªä¿ç•™æœ€é«˜åŒ¹é…çš„è©•è«–
            "weight": row["weight"]
        })

    return results


if __name__ == "__main__":
    # **æ¸¬è©¦ FAISS æª¢ç´¢**
    test_locations = []
    test_keywords = []

    print("\nğŸ” æ¸¬è©¦ FAISS èªæ„æª¢ç´¢...")
    faiss_results = retrieve_similar_places(test_locations, test_keywords)

    if faiss_results:
        print("\nâœ… FAISS æª¢ç´¢çµæœï¼ˆæœ€å¤š 10 æ¢ï¼‰ï¼š")
        for idx, row in enumerate(faiss_results):
            print(f"{idx+1}. ğŸ“ {row['gmap_location']}")
            print(f"   ğŸ’¬ {row['comments']}")
            print(f"   âš–ï¸  ç›¸ä¼¼åº¦æ¬Šé‡: {row['weight']:.4f}")
            print("-" * 60)
    else:
        print("âŒ æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„è©•è«–ã€‚")
